{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "d1jvXBfCDRqN"
      },
      "source": [
        "# DISCRIMINANT ANALYSIS\n",
        "\n",
        "In this coding assignment you are to implement a Minimum Risk Bayes Decision Theoretic classifier. Use the training set to train the classifier and the validation set to evaluate the accuracy. \n",
        "\n",
        "Assume the following:\n",
        "1. All conditional density functions are multivariate Gaussian\n",
        "2. Each class has its own covariance matrix\n",
        "3. Equally likely prior probabilities\n",
        "4. 0-1 loss function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d-qRoESDRqP"
      },
      "source": [
        "## Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5tFsCiqDRqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64cbdb36-f2e4-4f84-d526-d6f8feff3ffa"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load training data - 135 observations, 4 features, 3 classes, \n",
        "df = pd.read_csv(\"iris_corrupted_training_dataset.csv\")\n",
        "print(df.head())\n",
        "df = df.values\n",
        "train_data = df\n",
        "\n",
        "# Load validation data - 15 samples\n",
        "df = pd.read_csv(\"iris_validation_dataset.csv\")\n",
        "print(df.head())\n",
        "df = df.values\n",
        "val_data = df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal_length   sepal_width   petal_length   petal_width   class\n",
            "0        5.7147        2.6743         3.2696       1.65440       2\n",
            "1        5.1734        3.7374         5.9442       3.00050       3\n",
            "2        7.3776        3.1505         3.3543       0.64839       2\n",
            "3        6.4908        2.3983         3.3917       1.54950       2\n",
            "4        6.8182        3.4016         4.7495       0.57970       3\n",
            "   sepal_length   sepal_width   petal_length   petal_width   class\n",
            "0           4.4           2.9            1.4           0.2       1\n",
            "1           6.7           3.0            5.2           2.3       3\n",
            "2           4.9           3.1            1.5           0.2       1\n",
            "3           5.1           2.5            3.0           1.1       2\n",
            "4           6.1           3.0            4.6           1.4       2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data1 = train_data[np.where(train_data[:,4]==1),:]  \n",
        "train_data2 = train_data[np.where(train_data[:,4]==2),:]\n",
        "train_data3 = train_data[np.where(train_data[:,4]==3),:]\n",
        "[i,j,k] = np.shape(train_data1)\n",
        "\n",
        "train_data1 = train_data1.reshape(j,k)  \n",
        "train_data2 = train_data2.reshape(j,k)\n",
        "train_data3 = train_data3.reshape(j,k)\n",
        "\n",
        "\n",
        "train_data1 = train_data1[:,0:4]\n",
        "train_data2 = train_data2[:,0:4]\n",
        "train_data3 = train_data3[:,0:4]\n",
        "\n",
        "\n",
        "\n",
        "u1,u2,u3 = [],[],[]\n",
        "\n",
        "\n",
        "for i in range(np.shape(train_data1)[1]):\n",
        "    u1.append(np.mean(train_data1[:,i]))\n",
        "    u2.append(np.mean(train_data2[:,i]))\n",
        "    u3.append(np.mean(train_data3[:,i]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cov1 = np.cov(np.transpose(train_data1))\n",
        "cov2 = np.cov(np.transpose(train_data2))\n",
        "cov3 = np.cov(np.transpose(train_data3))\n",
        "\n",
        "\n",
        "D1 = np.linalg.det(cov1)\n",
        "D2 = np.linalg.det(cov2)\n",
        "D3 = np.linalg.det(cov3)\n",
        "l1 = np.log(D1)\n",
        "l2 = np.log(D2)\n",
        "l3 = np.log(D3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "I1 = np.linalg.inv(cov1)\n",
        "I2 = np.linalg.inv(cov2)\n",
        "I3 = np.linalg.inv(cov3)\n",
        "\n",
        "\n",
        "\n",
        "log_prior = np.log(1/3)"
      ],
      "metadata": {
        "id": "25yB3y3oSIxO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(u1)\n",
        "print(u2)\n",
        "print(u3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR9Nvh9bgeAK",
        "outputId": "7802d2d7-ee3b-4168-bbd5-992b8fc44ca0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.800817777777778, 3.4879955555555555, 1.2692098888888892, 0.34787733333333337]\n",
            "[6.065882222222222, 2.8228797777777777, 4.262413333333333, 1.1078519666666666]\n",
            "[6.42966, 2.956569555555556, 5.558746666666666, 1.9247654666666667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "correct_class = 0;  \n",
        "\n",
        "for i in range(0, len(val_data)):\n",
        "    \n",
        "    \n",
        "    x = val_data[i,0:4]  \n",
        "    y = val_data[i,4]    \n",
        "    \n",
        "    \n",
        "    g1 = - (0.5)* np.dot(np.dot(np.transpose(x-u1),I1),(x-u1)) - (0.5)*l1 + log_prior\n",
        "    g2 = - (0.5)* np.dot(np.dot(np.transpose(x-u2),I2),(x-u2)) - (0.5)*l2 + log_prior\n",
        "    g3 = - (0.5)* np.dot(np.dot(np.transpose(x-u3),I3),(x-u3)) - (0.5)*l3 + log_prior\n",
        "\n",
        "\n",
        "     \n",
        "    \n",
        "    g = [g1,g2,g3]\n",
        "    if(max(g)==g1):\n",
        "        yhat=1\n",
        "    elif(max(g)==g2):\n",
        "        yhat = 2\n",
        "    else:\n",
        "        yhat=3\n",
        "    \n",
        "    if (yhat == y):\n",
        "        correct_class = correct_class + 1;\n",
        "\n",
        "\n",
        "\n",
        "print('Classification accuracy = ', '{0:.4f}'. format(correct_class/15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHK6Pcmmgk0A",
        "outputId": "0eceef3f-6b5b-4654-d822-05da58f12cba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification accuracy =  0.9333\n"
          ]
        }
      ]
    }
  ]
}